{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim.downloader as api\n",
    "\n",
    "info = api.info()  # show info about available models/datasets\n",
    "model = api.load(\"glove-twitter-25\")  # download the model and return as object ready for use\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Readme here:\n",
    "https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use here the dataset provided by the authors we will create a helper function to extract the features that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"diplomacy_data/diplomacy_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_support(entry):\n",
    "    \"\"\"\n",
    "    This function returns the last season of friendship. The code is inspired by the provided code from\n",
    "    the authors\n",
    "    \"\"\"\n",
    "    last_support = None\n",
    "    for season in entry[:-1]:\n",
    "        if 'support' in season['interaction'].values():\n",
    "            last_support = season['season']\n",
    "    return last_support\n",
    "\n",
    "def treat_msg_season(df):\n",
    "    \"\"\"\n",
    "    This function loops over the whole dataset and creates a dictionnary with the set of features for each season with \n",
    "    its associated boolean (betrayal or not )\n",
    "    \"\"\"\n",
    "    tab_vi = []\n",
    "    data_victim = {'features':[], 'betrayed':[]} # data of the (potential) victim \n",
    "    data_betrayer = {'features':[], 'betrayed':[]} # data of the (potential) betrayer\n",
    "    for i in range(len(df.seasons.values)):\n",
    "        entry = df['seasons'][i] # pick each entry\n",
    "        for j in range(len(entry)): # pick each season\n",
    "            season = entry[j]\n",
    "            tab_vi = []\n",
    "            tab_be = []\n",
    "            if season['season'] <= last_support(entry): # check if the season is below the last season of friendship\n",
    "                tab_vi.append(season['messages']['victim'])\n",
    "                tab_be.append(season['messages']['betrayer'])\n",
    "                if len(tab_be) != 0 and len(tab_vi) != 0: # keep only cases where both players have sent messages\n",
    "                    data_victim['features'].append(tab_vi)\n",
    "                    data_victim['betrayed'].append(df.betrayal.values[i])\n",
    "                    data_betrayer['features'].append(tab_be)   \n",
    "                    data_betrayer['betrayed'].append(df.betrayal.values[i])\n",
    "    return data_victim, data_betrayer\n",
    "\n",
    "data_victim, data_betrayer = treat_msg_season(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In each season, potential betrayers send in average 1.627498001598721, with a maximum of 38 messages\n",
      "In each season, potential victims send in average 1.515587529976019, with a maximum of 28 messages\n"
     ]
    }
   ],
   "source": [
    "def get_nb_msg(data):\n",
    "    \"\"\"\n",
    "    Get the mean number of messages sent per season\n",
    "    \"\"\"\n",
    "    tab = []\n",
    "    for features in data[\"features\"]:\n",
    "        tab.append(len(features[0]))\n",
    "    return tab\n",
    "\n",
    "print(\"In each season, potential betrayers send in average {}, with a maximum of {} messages\".format(np.mean(get_nb_msg(data_betrayer)), np.max(get_nb_msg(data_betrayer))))\n",
    "print(\"In each season, potential victims send in average {}, with a maximum of {} messages\".format(np.mean(get_nb_msg(data_victim)), np.max(get_nb_msg(data_victim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lexicon_words(entry):\n",
    "    \"\"\"\n",
    "    get the set of lexicon words for each entry of the dataset\n",
    "    1 entry = 1 row = 1 set of messages\n",
    "    Can be improved\n",
    "    \"\"\"\n",
    "    for entries in entry[0]: #loop over the messages\n",
    "        # get the lexicon words\n",
    "        di_words = entries[\"lexicon_words\"]\n",
    "        tab_words = []\n",
    "        for key in di_words:\n",
    "            tab = di_words[key]\n",
    "            for words in tab:\n",
    "                word = words.split(' ')\n",
    "                for w in word:\n",
    "                    if w not in tab_words:\n",
    "                        tab_words.append(w)\n",
    "    return tab_words\n",
    "\n",
    "test = get_lexicon_words(data_victim[\"features\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement : remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy & Glove word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the spacy library to compute the embeddings. We have to try also with Glove and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word :still , embedding : [-0.22114   0.67529   0.59344  -1.0235   -0.6578    0.64357   1.6461\n",
      " -0.13754  -0.20652   0.41388  -0.12224   0.92581  -5.0168   -0.11061\n",
      "  0.034176  0.35356   0.027989 -0.55968  -0.2286   -0.79967   0.58868\n",
      "  0.56942   0.29349   0.3104   -0.50146 ]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def get_word_embedding(word):\n",
    "    return nlp(word).vector\n",
    "\n",
    "def get_word_embedding_model(model, word):\n",
    "    return model[word]\n",
    "\n",
    "print(\"Word :{} , embedding : {}\".format(test[1], get_word_embedding_model(model, test[1])))\n",
    "#model.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stego",
   "language": "python",
   "name": "stego"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
