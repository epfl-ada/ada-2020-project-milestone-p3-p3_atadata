{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import gensim.downloader as api\n",
    "\n",
    "info = api.info()  # show info about available models/datasets\n",
    "model = api.load(\"glove-twitter-25\")  # download the model and return as object ready for use\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the Readme here:\n",
    "https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use here the dataset provided by the authors we will create a helper function to extract the features that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seasons</th>\n",
       "      <th>game</th>\n",
       "      <th>betrayal</th>\n",
       "      <th>idx</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'season': 1906.5, 'interaction': {'victim': ...</td>\n",
       "      <td>74</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'season': 1911.5, 'interaction': {'victim': ...</td>\n",
       "      <td>165</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'season': 1911.0, 'interaction': {'victim': ...</td>\n",
       "      <td>157</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'season': 1902.0, 'interaction': {'victim': ...</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'season': 1910.0, 'interaction': {'victim': ...</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>[{'season': 1908.0, 'interaction': {'victim': ...</td>\n",
       "      <td>197</td>\n",
       "      <td>False</td>\n",
       "      <td>495</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>[{'season': 1911.5, 'interaction': {'victim': ...</td>\n",
       "      <td>207</td>\n",
       "      <td>True</td>\n",
       "      <td>496</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>[{'season': 1905.5, 'interaction': {'victim': ...</td>\n",
       "      <td>158</td>\n",
       "      <td>True</td>\n",
       "      <td>497</td>\n",
       "      <td>RE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>[{'season': 1903.0, 'interaction': {'victim': ...</td>\n",
       "      <td>252</td>\n",
       "      <td>True</td>\n",
       "      <td>498</td>\n",
       "      <td>GE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>[{'season': 1903.5, 'interaction': {'victim': ...</td>\n",
       "      <td>253</td>\n",
       "      <td>True</td>\n",
       "      <td>499</td>\n",
       "      <td>FG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               seasons  game  betrayal  idx  \\\n",
       "0    [{'season': 1906.5, 'interaction': {'victim': ...    74      True    0   \n",
       "1    [{'season': 1911.5, 'interaction': {'victim': ...   165     False    1   \n",
       "2    [{'season': 1911.0, 'interaction': {'victim': ...   157     False    2   \n",
       "3    [{'season': 1902.0, 'interaction': {'victim': ...    58     False    3   \n",
       "4    [{'season': 1910.0, 'interaction': {'victim': ...    45     False    4   \n",
       "..                                                 ...   ...       ...  ...   \n",
       "495  [{'season': 1908.0, 'interaction': {'victim': ...   197     False  495   \n",
       "496  [{'season': 1911.5, 'interaction': {'victim': ...   207      True  496   \n",
       "497  [{'season': 1905.5, 'interaction': {'victim': ...   158      True  497   \n",
       "498  [{'season': 1903.0, 'interaction': {'victim': ...   252      True  498   \n",
       "499  [{'season': 1903.5, 'interaction': {'victim': ...   253      True  499   \n",
       "\n",
       "    people  \n",
       "0       AT  \n",
       "1       EG  \n",
       "2       AR  \n",
       "3       AR  \n",
       "4       IT  \n",
       "..     ...  \n",
       "495     RT  \n",
       "496     AR  \n",
       "497     RE  \n",
       "498     GE  \n",
       "499     FG  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"diplomacy_data/diplomacy_data.json\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [{'season': 1906.5, 'interaction': {'victim': ...\n",
       "1      [{'season': 1911.5, 'interaction': {'victim': ...\n",
       "2      [{'season': 1911.0, 'interaction': {'victim': ...\n",
       "3      [{'season': 1902.0, 'interaction': {'victim': ...\n",
       "4      [{'season': 1910.0, 'interaction': {'victim': ...\n",
       "                             ...                        \n",
       "495    [{'season': 1908.0, 'interaction': {'victim': ...\n",
       "496    [{'season': 1911.5, 'interaction': {'victim': ...\n",
       "497    [{'season': 1905.5, 'interaction': {'victim': ...\n",
       "498    [{'season': 1903.0, 'interaction': {'victim': ...\n",
       "499    [{'season': 1903.5, 'interaction': {'victim': ...\n",
       "Name: seasons, Length: 500, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['seasons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_support(entry):\n",
    "    \"\"\"\n",
    "    This function returns the last season of friendship. The code is inspired by the provided code from\n",
    "    the authors\n",
    "    \"\"\"\n",
    "    last_support = None\n",
    "    for season in entry[:-1]:\n",
    "        if 'support' in season['interaction'].values():\n",
    "            last_support = season['season']\n",
    "    return last_support\n",
    "\n",
    "def treat_msg_season(df):\n",
    "    \"\"\"\n",
    "    This function loops over the whole dataset and creates a dictionnary with the set of features for each season \n",
    "    with its associated boolean (betrayal or not )\n",
    "    \"\"\"\n",
    "    data_victim = {'features':[], 'betrayed':[]} # data of the (potential) victim \n",
    "    data_betrayer = {'features':[], 'betrayed':[]} # data of the (potential) betrayer\n",
    "    for i in range(len(df.seasons.values)):\n",
    "        entry = df['seasons'][i] # pick each entry\n",
    "        for j in range(len(entry)): # pick each season\n",
    "            season = entry[j]\n",
    "            tab_vi = []\n",
    "            tab_be = []\n",
    "            if season['season'] <= last_support(entry): # check if the season is below the last season of friendship\n",
    "                tab_vi.append(season['messages']['victim'])\n",
    "                tab_be.append(season['messages']['betrayer'])\n",
    "                if len(tab_be) != 0 and len(tab_vi) != 0: # keep only cases where both players have sent messages\n",
    "                    data_victim['features'].append(tab_vi)\n",
    "                    data_victim['betrayed'].append(df.betrayal.values[i])\n",
    "                    data_betrayer['features'].append(tab_be)   \n",
    "                    data_betrayer['betrayed'].append(df.betrayal.values[i])\n",
    "    return data_victim, data_betrayer\n",
    "\n",
    "data_victim, data_betrayer = treat_msg_season(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(message):\n",
    "    sentiment_positive = message['sentiment']['positive']\n",
    "    sentiment_neutral = message['sentiment']['neutral']\n",
    "    sentiment_negative = message['sentiment']['negative']\n",
    "    n_requests = message['n_requests']\n",
    "    frequent_words = message['frequent_words']\n",
    "    n_words = message['n_words']\n",
    "    politeness = message['politeness']\n",
    "    n_sentences = message['n_sentences']\n",
    "    return {\"sentiment_positive\": sentiment_positive,\n",
    "           \"sentiment_neutral\": sentiment_neutral,\n",
    "           'sentiment_negative': sentiment_negative,\n",
    "           'n_requests': n_requests,\n",
    "           'frequent_words': frequent_words,\n",
    "           'n_words': n_words,\n",
    "           'politeness': politeness,\n",
    "           'n_sentences': n_sentences}\n",
    "    \n",
    "\n",
    "\n",
    "def preprocessing(df):\n",
    "    result = []\n",
    "    for row in df.iterrows():\n",
    "        row = row[1]\n",
    "        betrayal = row['betrayal']\n",
    "        idx = row['idx']\n",
    "        for season in row['seasons']:\n",
    "            s = season['season']\n",
    "            if s < last_support(row['seasons']):\n",
    "                interaction_vitim = season['interaction']['victim']\n",
    "                interaction_betrayer = season ['interaction']['betrayer']\n",
    "                for m_vic in season['messages']['victim']:\n",
    "                    data = to_dict(m_vic)\n",
    "                    data['role'] = 'victim'\n",
    "                    data['season'] = s\n",
    "                    data['betrayal'] = betrayal\n",
    "                    data['idx'] = idx\n",
    "                    result.append(data)\n",
    "                for m_bet in season['messages']['betrayer']:\n",
    "                    data = to_dict(m_bet)\n",
    "                    data['role'] = 'betrayer'\n",
    "                    data['season'] = s\n",
    "                    data['betrayal'] = betrayal\n",
    "                    data['idx'] = idx\n",
    "                    result.append(data)\n",
    "                            \n",
    "    return pd.DataFrame(result).set_index(['idx', 'season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentiment_positive</th>\n",
       "      <th>sentiment_neutral</th>\n",
       "      <th>sentiment_negative</th>\n",
       "      <th>n_requests</th>\n",
       "      <th>frequent_words</th>\n",
       "      <th>n_words</th>\n",
       "      <th>politeness</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>role</th>\n",
       "      <th>betrayal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1906.5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[just, bot, ,, ., take, unit, war, retreat, di...</td>\n",
       "      <td>35</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>2</td>\n",
       "      <td>victim</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906.5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[armies, north, the, armies, on, ., your, with...</td>\n",
       "      <td>77</td>\n",
       "      <td>0.932326</td>\n",
       "      <td>6</td>\n",
       "      <td>victim</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906.5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[?, going, for, ser, balance, a, to, of, give,...</td>\n",
       "      <td>55</td>\n",
       "      <td>0.983373</td>\n",
       "      <td>4</td>\n",
       "      <td>victim</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906.5</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>[only, he, alb, ., forced, italy's, is, be, .,...</td>\n",
       "      <td>313</td>\n",
       "      <td>0.957072</td>\n",
       "      <td>19</td>\n",
       "      <td>victim</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906.5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>[more, let, keep, we, side, we, don't, to, ., ...</td>\n",
       "      <td>146</td>\n",
       "      <td>0.832023</td>\n",
       "      <td>9</td>\n",
       "      <td>betrayer</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">499</th>\n",
       "      <th>1904.0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[he, on, please, kaiser, italy, ..., ., move, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.323602</td>\n",
       "      <td>3</td>\n",
       "      <td>victim</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[request, can, as, save, i, ., your, consider,...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.777903</td>\n",
       "      <td>3</td>\n",
       "      <td>betrayer</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[do, ?, the, ,, things, thing, ,, taking, both...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.599901</td>\n",
       "      <td>1</td>\n",
       "      <td>betrayer</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904.0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[!!, !, and, dmz, win, agreed, ok, ,, you, all...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.389337</td>\n",
       "      <td>3</td>\n",
       "      <td>betrayer</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[my, am, you, your, defense, from, messages, a...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.274772</td>\n",
       "      <td>2</td>\n",
       "      <td>betrayer</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6508 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment_positive  sentiment_neutral  sentiment_negative  \\\n",
       "idx season                                                              \n",
       "0   1906.5                   0                  0                   2   \n",
       "    1906.5                   1                  1                   4   \n",
       "    1906.5                   1                  2                   1   \n",
       "    1906.5                   4                  2                  13   \n",
       "    1906.5                   1                  3                   5   \n",
       "...                        ...                ...                 ...   \n",
       "499 1904.0                   0                  3                   0   \n",
       "    1904.0                   1                  0                   2   \n",
       "    1904.0                   0                  0                   1   \n",
       "    1904.0                   1                  2                   0   \n",
       "    1904.0                   0                  0                   2   \n",
       "\n",
       "            n_requests                                     frequent_words  \\\n",
       "idx season                                                                  \n",
       "0   1906.5           1  [just, bot, ,, ., take, unit, war, retreat, di...   \n",
       "    1906.5           2  [armies, north, the, armies, on, ., your, with...   \n",
       "    1906.5           2  [?, going, for, ser, balance, a, to, of, give,...   \n",
       "    1906.5           8  [only, he, alb, ., forced, italy's, is, be, .,...   \n",
       "    1906.5           7  [more, let, keep, we, side, we, don't, to, ., ...   \n",
       "...                ...                                                ...   \n",
       "499 1904.0           0  [he, on, please, kaiser, italy, ..., ., move, ...   \n",
       "    1904.0           2  [request, can, as, save, i, ., your, consider,...   \n",
       "    1904.0           1  [do, ?, the, ,, things, thing, ,, taking, both...   \n",
       "    1904.0           0  [!!, !, and, dmz, win, agreed, ok, ,, you, all...   \n",
       "    1904.0           1  [my, am, you, your, defense, from, messages, a...   \n",
       "\n",
       "            n_words  politeness  n_sentences      role  betrayal  \n",
       "idx season                                                        \n",
       "0   1906.5       35    0.367200            2    victim      True  \n",
       "    1906.5       77    0.932326            6    victim      True  \n",
       "    1906.5       55    0.983373            4    victim      True  \n",
       "    1906.5      313    0.957072           19    victim      True  \n",
       "    1906.5      146    0.832023            9  betrayer      True  \n",
       "...             ...         ...          ...       ...       ...  \n",
       "499 1904.0       12    0.323602            3    victim      True  \n",
       "    1904.0       32    0.777903            3  betrayer      True  \n",
       "    1904.0       22    0.599901            1  betrayer      True  \n",
       "    1904.0       13    0.389337            3  betrayer      True  \n",
       "    1904.0       19    0.274772            2  betrayer      True  \n",
       "\n",
       "[6508 rows x 10 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocessing(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In each season, potential betrayers send in average 1.627498001598721, with a maximum of 38 messages\n",
      "In each season, potential victims send in average 1.515587529976019, with a maximum of 28 messages\n"
     ]
    }
   ],
   "source": [
    "def get_nb_msg(data):\n",
    "    \"\"\"\n",
    "    Get the mean number of messages sent per season\n",
    "    \"\"\"\n",
    "    tab = []\n",
    "    for features in data[\"features\"]:\n",
    "        tab.append(len(features[0]))\n",
    "    return tab\n",
    "\n",
    "print(\"In each season, potential betrayers send in average {}, with a maximum of {} messages\".format(np.mean(get_nb_msg(data_betrayer)), np.max(get_nb_msg(data_betrayer))))\n",
    "print(\"In each season, potential victims send in average {}, with a maximum of {} messages\".format(np.mean(get_nb_msg(data_victim)), np.max(get_nb_msg(data_victim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'sentiment': {'positive': 0, 'neutral': 0, 'negative': 2}, 'lexicon_words': {'allsubj': ['just', 'war', 'prefer', 'really', 'light', 'retreat'], 'premise': ['in light of']}, 'n_requests': 1, 'frequent_words': ['just', 'bot', ',', '.', 'take', 'unit', 'war', 'retreat', \"didn't\", 'to', 'turn', 'really', 'mos', 'from', '.', ',', 'nwy', 'prefer', 'using', 'stp', 'if', 'that', 'of', 'i', 'can', 'and', 'me', 'in', \"i'd\", 'your', 'this'], 'n_words': 35, 'politeness': 0.36720018621437905, 'n_sentences': 2}, {'sentiment': {'positive': 1, 'neutral': 1, 'negative': 4}, 'lexicon_words': {'allsubj': ['against', 'lose', 'even', 'loss', 'support', 'attack', 'good', 'will'], 'disc_expansion': ['later', 'next'], 'disc_comparison': ['after'], 'disc_temporal_future': ['next', 'after', 'later'], 'premise': ['for', 'for']}, 'n_requests': 2, 'frequent_words': ['armies', 'north', 'the', 'armies', 'on', '.', 'your', 'with', 'mos', 'we', 'against', 'the', ',', '.', \"i'll\", 'be', ',', 'after', 'sounds', '.', 'to', 'this', \"won't\", 'with', '.', 'this', '.', 'you', 'in', 'loss', 'support', 'for', 'i', 'armies', 'plan', 'fleets', 'use', 'my', 'france', 'my', 'good', 'turn', 'and', 'cheers', 'in', 'attack', 'in', 'southern', 'lose', '.', 'fleets', 'will', 'moves', 'and', 'any', 'later', 'even', 'can', 'going', 'an', 'south', 'the', 'my', 'france', \"i'll\", 'be', 'next', 'with', 'in', 'for', 'europe', 'of', 'germany'], 'n_words': 77, 'politeness': 0.932325946878584, 'n_sentences': 6}, {'sentiment': {'positive': 1, 'neutral': 2, 'negative': 1}, 'lexicon_words': {'allsubj': ['rather', 'light', 'would', 'lose', 'retreat', 'could', 'perhaps'], 'disc_expansion': ['rather'], 'disc_comparison': ['rather', 'after'], 'disc_temporal_future': ['after'], 'premise': ['in light of', 'for', 'as']}, 'n_requests': 2, 'frequent_words': ['?', 'going', 'for', 'ser', 'balance', 'a', 'to', 'of', 'give', '.', 'the', 'supply', 'in', 'mos', 'you', 'you', 'it', 'as', 'stp', 'rather', '...', 'to', 'to', 'retreat', 'be', 'could', 'out', '.', \"i'd\", ',', 'about', 'your', 'appreciated', 'lose', 'or', 'would', 'center', ',', 'germany', 'after', 'me', 'thanks', 'this', 'a', 'bud', 'i', 'there', 'and', 'perhaps'], 'n_words': 55, 'politeness': 0.9833733938861081, 'n_sentences': 4}, {'sentiment': {'positive': 4, 'neutral': 2, 'negative': 13}, 'lexicon_words': {'claim': ['so', 'so'], 'disc_temporal_rest': ['before', 'while', 'before', 'still', 'as long as'], 'allsubj': ['interesting', 'deprive', 'retreat', 'attack', 'so', 'suggest', 'move', 'expose', 'beneficial', 'think', 'support', 'like', 'protect', 'like', 'nap', 'better', 'alliance', 'glad', 'even', 'wise', 'fine', 'convince', 'so', 'surely', 'think', 'really', 'retreat', 'trustworthy', 'comfortable', 'must', 'ally', 'nap', 'battle', 'will', 'move', 'excellent', 'war', 'nap', 'long', 'much', 'nap', 'still', 'like', 'lack', 'worth', 'even', 'would'], 'disc_expansion': ['while'], 'disc_contingency': ['as long as'], 'premise': ['for', 'as', 'for', 'as', 'for', 'as', 'as', 'due to', 'for', 'as', 'for', 'for', 'for'], 'disc_comparison': ['still', 'while']}, 'n_requests': 8, 'frequent_words': ['only', 'he', 'alb', '.', 'forced', \"italy's\", 'is', 'be', '.', 'worth', 'ion', 'before', 'can', '.', 'lack', 'tys', 'i', 'so', 'rom', \"'\", 'as', 'from', 'ally', \"'\", 'of', 'and', 'nap', 'the', 'ion', 'is', 'like', 'in', 'comfortable', 'aeg', 'fleet', 'our', 'and', 'the', 'gre', 'to', 'for', 'like', 'me', 'to', 'move', 'even', 'your', '-', 'he', 'must', 'on', 'think', 'a', 'to', 'be', 'our', 'this', '.', '.', '.', 'ion', 'pru', 'centers', 'army', 'of', 'on', 'it', 'alliance', 'a', 'even', 'mos', 'it', 'supply', 'army', 'stp', 'interesting', \"you've\", 'can', 's', 'a', 'tun', 'one', 'if', 'suggest', ':', 'with', 'turn', 'to', 'as', '.', 'hear', 'gre', 'be', 'be', 'a', 'others', 'for', 'the', 'nap', 'to', 'and', 'stuck', 'i', 'seems', 'f', 'you', '-', '-', 'f', 'units', 'war', 'protect', 'out', 'due', ':', 'you', 'here', 'fine', ',', 's', 'is', 'is', 'better', 'while', 'battle', ')', 'of', 'lvn', 'retreat', 'build', \"i'm\", 'this', 'his', 'planning', 'at', 'of', 'with', 'several', 'to', 'glad', ',', 'in', 'vs', 'if', 'that', '-', \"don't\", 'for', 'gre', 'for', 'get', 'ion', '.', 'your', 'to', 'an', 'for', 'sil', 'to', 'up', '-', 'mos', 'nap', '.', \"we're\", 'doing', 'you', \"we're\", 'other', 'f', 'the', 'to', 'you', 'if', 'if', 'has', '-', 'out', '.', 'for', 'my', 'of', 'have', 'f', 'would', 'or', 'this', 'really', ',', 'rom', 'apu', 'will', 'to', 'excellent', 'turns', 'more', '.', 'it', 'working', 'it', 'gre', 'south', 'convince', 'looks', 'like', 'for', 'works', 'end', \"he'll\", ',', '.', 'that', 'turn', 'support', 'that', 'think', 'a', 'this', 'action', 'as', 'much', 'movement', 'leaves', 'been', 'on', 'attack', 'as', 'i', 'moves', 'cheers', 'f', ',', '.', 'each', ',', '...', 'home', \"you'd\", 'is', 'move', 'put', 'looks', 'long', 'at', '.', 'was', 'far', 'fleet', '-', \"i'd\", 'my', 'nap', 'my', '.', 'italy', 'so', 'f', 'italy', 'before', 'we', 'others', '.', '...', 'to', 'to', 'it', 'still', 'a', 'is', 'a', 'rom', '-', 'be', '.', 'what', 'remove', 'retreat', 's', 'as', 'me', 'ion', 'he', '(', '-', 'go'], 'n_words': 313, 'politeness': 0.9570724545762411, 'n_sentences': 19}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9e9317db20e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtab_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lexicon_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_victim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-9e9317db20e1>\u001b[0m in \u001b[0;36mget_lexicon_words\u001b[0;34m(entry)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# get the lexicon words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdi_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lexicon_words\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtab_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdi_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "def get_lexicon_words(entry):\n",
    "    \"\"\"\n",
    "    get the set of lexicon words for each entry of the dataset\n",
    "    1 entry = 1 row = 1 set of messages\n",
    "    Can be improved\n",
    "    \"\"\"\n",
    "    for entries in entry[0]: #loop over the messages\n",
    "        # get the lexicon words\n",
    "        di_words = entries[\"lexicon_words\"]\n",
    "        tab_words = []\n",
    "        for key in di_words:\n",
    "            tab = di_words[key]\n",
    "            for words in tab:\n",
    "                word = words.split(' ')\n",
    "                for w in word:\n",
    "                    if w not in tab_words:\n",
    "                        tab_words.append(w)\n",
    "    return tab_words\n",
    "\n",
    "test = get_lexicon_words(data_victim[\"features\"][-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open(\"helpers/stopwords.txt\", encoding='utf-8') as h:\n",
    "    stopwords = h.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy & Glove word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the spacy library to compute the embeddings. We have to try also with Glove and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word :still , embedding : [-0.22114   0.67529   0.59344  -1.0235   -0.6578    0.64357   1.6461\n",
      " -0.13754  -0.20652   0.41388  -0.12224   0.92581  -5.0168   -0.11061\n",
      "  0.034176  0.35356   0.027989 -0.55968  -0.2286   -0.79967   0.58868\n",
      "  0.56942   0.29349   0.3104   -0.50146 ]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def get_word_embedding(word):\n",
    "    return nlp(word).vector\n",
    "\n",
    "def get_word_embedding_model(model, word):\n",
    "    return model[word]\n",
    "\n",
    "print(\"Word :{} , embedding : {}\".format(test[1], get_word_embedding_model(model, test[1])))\n",
    "#model.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
